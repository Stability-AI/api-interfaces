syntax = 'proto3';
package gooseai;
option go_package = "github.com/stability-ai/api-interfaces/gooseai/generation";
import "google/protobuf/struct.proto";
import "tensors.proto";

enum FinishReason {
  NULL = 0;
  LENGTH = 1;
  STOP = 2;
  ERROR = 3;
  FILTER = 4;
}

enum ArtifactType {
  ARTIFACT_NONE = 0;
  ARTIFACT_IMAGE = 1;
  ARTIFACT_VIDEO = 2;
  ARTIFACT_TEXT = 3;
  ARTIFACT_TOKENS = 4;
  ARTIFACT_EMBEDDING = 5;
  ARTIFACT_CLASSIFICATIONS = 6;
  ARTIFACT_MASK = 7;
  ARTIFACT_LATENT = 8;
  ARTIFACT_TENSOR = 9;
  ARTIFACT_DEPTH = 10;
}

// Generally, a GPT BPE 16-bit token, paired with an optional string representation.
message Token {
  optional string text = 1;
  uint32 id = 2;
}

// Sequence of tokens, paired with the id of the tokenizer used to generate them.
message Tokens {
  repeated Token tokens = 1;
  optional string tokenizer_id = 2;
}

// A tangible Artifact, such as an image, video, or text that is used for input
// or output.
message Artifact {
  uint64 id = 1;
  ArtifactType type = 2;
  string mime = 3;                // MIME type identifier, e.g. "image/png"
  optional string magic = 4;      // Magic number, e.g. "PNG"
  oneof data {
    bytes binary = 5;             // Binary data, e.g. PNG image
    string text = 6;              // Text data, e.g. text prompt
    Tokens tokens = 7;            // Tokenized text data, e.g. GPT tokens
    ClassifierParameters classifier = 11;
    tensors.Tensor tensor = 14;   // torch.Tensor:
                                  //    RGB tensor (C,H,W)
                                  //    VAE latent (C,H//8,W//8, assuming VAE-f8)
  }
  uint32 index = 8;               // Index of this artifact in input/output list
  FinishReason finish_reason = 9; // Reason for finishing, if applicable
  uint32 seed = 10;               // Seed used to generate this artifact
  string uuid = 12;               // UUIDv4 of the artifact, used for asset lookup
  uint64 size = 13;               // Size of the artifact in bytes
}

enum MaskedAreaInit {
  MASKED_AREA_INIT_ZERO = 0;
  MASKED_AREA_INIT_RANDOM = 1;
  MASKED_AREA_INIT_ORIGINAL = 2;
}

enum WeightMethod {
  TEXT_ENCODER = 0;
  CROSS_ATTENTION = 1;
}

// A set of parameters for each individual Prompt.
message PromptParameters {
  optional bool init = 1;     // deprecated, no longer used
  optional float weight = 2;
}

// A Prompt is a special type of Artifact that is used to generate an output.
// There can be multiple Prompts that affect the same output. Currently, the
// only Prompts supported are:
//   - Text (singular)
//   - Init Image (singular, optional, type ARTIFACT_IMAGE)
//   - Mask (singular, optional, type ARTIFACT_MASK)
//   - Depth (singular, optional, type ARTIFACT_DEPTH)
message Prompt {
  optional PromptParameters parameters = 1;
  oneof prompt {
    string text = 2;
    Tokens tokens = 3;
    Artifact artifact = 4;
  }
}

// DiffusionSampler identifies which sampler to use for Diffusion, and represents
// the internal set of supported samplers.
enum DiffusionSampler {
  SAMPLER_DDIM = 0;
  SAMPLER_DDPM = 1;
  SAMPLER_K_EULER = 2;
  SAMPLER_K_EULER_ANCESTRAL = 3;
  SAMPLER_K_HEUN = 4;
  SAMPLER_K_DPM_2 = 5;
  SAMPLER_K_DPM_2_ANCESTRAL = 6;
  SAMPLER_K_LMS = 7;
  SAMPLER_K_DPMPP_2S_ANCESTRAL = 8;
  SAMPLER_K_DPMPP_2M = 9;
  SAMPLER_K_DPMPP_SDE = 10;
}

// Parameters that affect the behavior of the sampler, typically used for CFG.
message SamplerParameters {
  optional float eta = 1;
  optional uint64 sampling_steps = 2;
  optional uint64 latent_channels = 3;
  optional uint64 downsampling_factor = 4;
  optional float cfg_scale = 5;
  optional float init_noise_scale = 6; // defaults to 0.99
  optional float step_noise_scale = 7; // defaults to 0.99
}

// Unused, but reserved for future use. Adjustments to the latents after
// initialization.
message ConditionerParameters {
  optional string vector_adjust_prior = 1;
  optional Model conditioner = 2;
}

// Future, unimplemented.
enum Upscaler {
  UPSCALER_RGB = 0;
  UPSCALER_GFPGAN = 1;
  UPSCALER_ESRGAN = 2;
}

// When does this schedule definition apply?
message ScheduleParameters {
  optional float start = 1;     // 0.0 to 1.0
  optional float end = 2;       // 0.0 to 1.0
  optional float value = 3;     // float value to apply on this schedule
}

// Parameters that apply to this block of the schedule.
message StepParameter {
  float scaled_step = 1;
  optional SamplerParameters sampler = 2;
  optional ScheduleParameters schedule = 3;
  optional GuidanceParameters guidance = 4;
}

// Presets for CLIP guidance.
enum GuidancePreset {
  GUIDANCE_PRESET_NONE = 0;
  GUIDANCE_PRESET_SIMPLE = 1;
  GUIDANCE_PRESET_FAST_BLUE = 2;
  GUIDANCE_PRESET_FAST_GREEN = 3;
  GUIDANCE_PRESET_SLOW = 4;
  GUIDANCE_PRESET_SLOWER = 5;
  GUIDANCE_PRESET_SLOWEST = 6;
}

enum ModelArchitecture {
  MODEL_ARCHITECTURE_NONE = 0;
  MODEL_ARCHITECTURE_CLIP_VIT = 1;
  MODEL_ARCHITECTURE_CLIP_RESNET = 2;
  MODEL_ARCHITECTURE_LDM = 3;
}

message Model {
  ModelArchitecture architecture = 1;
  string publisher = 2;
  string dataset = 3;
  float version = 4;
  string semantic_version = 5;
  string alias = 6;
}

message CutoutParameters {
  repeated CutoutParameters cutouts = 1;    // Nested cutouts, unsupported
  optional uint32 count = 2;                // 0 to n, usually 8 to 32, 0 inner
  optional float gray = 3;                       // 0.0 to 1.0, defaults to 0.2
  optional float blur = 4;                       // percentage of cutouts to blur
  optional float size_power = 5;            // defaults to inner: 0.5, outer: 0.0
}

// GuidanceScheduleParameters are used to define a schedule for CLIP guidance, and
// are used to define the behavior of the guidance over time. They are relative
// to the total number of steps, and are scaled to the number of steps in the
// current run.
message GuidanceScheduleParameters {
  float duration = 1;
  float value = 2;
}

// Parameters that affect the behavior of the guidance, typically used for CLIP.
// We can specify more than one model, and the guidance will be a weighted sum
// of the models.
message GuidanceInstanceParameters {
  repeated Model models = 2;                // models to use for this set
  optional float guidance_strength = 3;     // 0.0 to 1.0, usually 0.05 to 0.225
  repeated GuidanceScheduleParameters schedule = 4; // when to apply guidance
  optional CutoutParameters cutouts = 5;    // cutout parameters
  optional Prompt prompt = 6;               // prompt to use for guidance
}

// Parameters that affect the behavior of the guidance, typically used for CLIP.
// The omission of this field implies the default guidance of CFG.
message GuidanceParameters {
  GuidancePreset guidance_preset = 1;                // base preset for guidance
  repeated GuidanceInstanceParameters instances = 2; // guidance instances
}

message TransformType {
  oneof type {
    DiffusionSampler diffusion = 1;
    Upscaler upscaler = 2;
  }
}

message ImageParameters {
  optional uint64 height = 1;
  optional uint64 width = 2;
  repeated uint32 seed = 3;
  optional uint64 samples = 4;
  optional uint64 steps = 5;
  optional TransformType transform = 6;
  repeated StepParameter parameters = 7;
  optional MaskedAreaInit masked_area_init = 8; // defaults to MASKED_AREA_INIT_ZERO
  optional WeightMethod weight_method = 9; //defaults to TEXT_ENCODER
  optional bool quantize = 10; //defaults to true
}

enum Action {
  ACTION_PASSTHROUGH = 0;
  ACTION_REGENERATE_DUPLICATE = 1;
  ACTION_REGENERATE = 2;
  ACTION_OBFUSCATE_DUPLICATE = 3;
  ACTION_OBFUSCATE = 4;
  ACTION_DISCARD = 5;
}

//
// Artifact classification parameters.
//

enum ClassifierMode {
  CLSFR_MODE_ZEROSHOT = 0;
  CLSFR_MODE_MULTICLASS = 1;
  /*CLSFR_MODE_ODDSRATIO = 2;*/
}

message ClassifierConcept {
  string concept = 1;
  optional float threshold = 2;
}

message ClassifierCategory {
  string name = 1;
  repeated ClassifierConcept concepts = 2;
  optional float adjustment = 3;
  optional Action action = 4;
  optional ClassifierMode classifier_mode = 5;
}

message ClassifierParameters {
  repeated ClassifierCategory categories = 1;
  repeated ClassifierCategory exceeds = 2;
  optional Action realized_action = 3;
}


//
// Interpolation
//

enum InterpolateMode {
  INTERPOLATE_LINEAR = 0;
  INTERPOLATE_RIFE = 1;
  INTERPOLATE_VAE_LINEAR = 2;
  INTERPOLATE_VAE_SLERP = 3;
}

// Interpolation between two images applied at specified blend ratios
message InterpolateParameters {
  repeated float ratios = 1;
  optional InterpolateMode mode = 2;
}


//
// Transforms
//

enum BorderMode {
  BORDER_REFLECT = 0;   // reflect image values across the border
  BORDER_REPLICATE = 1; // replicate border values outside the image
  BORDER_WRAP = 2;      // wrap around / tile the image values
  BORDER_ZERO = 3;      // use 0 for locations outside the image
  BORDER_PREFILL = 4;   // prefill border areas with values matching the colors around the area
}

enum ColorMatchMode {
  COLOR_MATCH_HSV = 0;  // match hue, saturation, and value histograms
  COLOR_MATCH_LAB = 1;  // match lightness, a, and b histograms
  COLOR_MATCH_RGB = 2;  // match red, green, and blue histograms
}

message TransformColorAdjust {
  optional float brightness = 1;          // scale pixel intensities, 1.0 is no change
  optional float contrast = 2;            // contrast adjustment, 1.0 is no change
  optional float hue = 3;                 // -180 to 180 hue adjustment, 0.0 is no change
  optional float saturation = 4;          // 0.0 to 2.0 saturation scale, 1.0 is no change
  optional float lightness = 5;           // -1.0 to 1.0 lightness adjustment, 0.0 is no change
  optional Artifact match_image = 6;      // image to color match
  optional ColorMatchMode match_mode = 7; // color match mode to use
  optional float noise_amount = 8;        // amount of gaussian noise to add
  optional uint32 noise_seed = 9;         // random seed for noise
}

message TransformDepthCalc {
  optional float blend_weight = 1; // blend factor between AdaBins (0.0) and MiDaS (1.0)
  optional uint32 blur_radius = 2; // defaults to 0.0
  optional bool reverse = 3;       // make near depths have higher values
}

message TransformMatrix {
  // Column-major 3x3 or 4x4 perspective matrix
  // [sx, 10, 20, tx]   [x]
  // [01, sy, 21, ty] . [y]
  // [02, 12, sz, tz]   [z]
  // [03, 13, 23, 33]   [1]
  repeated float data = 1 [packed=true];
}

message TransformResample {
  BorderMode border_mode = 1;                  // extrapolation of border pixels
  TransformMatrix transform = 2;               // 3x3 or 4x4 matrix
  optional TransformMatrix prev_transform = 3; // 3x3 or 4x4 matrix, defaults to identity
  optional float depth_warp = 4;               // depth warp factor, defaults to 1.0
  optional bool export_mask = 5;               // return inpaint mask
}

message PointCloudRenderParameters {
  float radius = 1;            // The radius (in NDC units) of each disk to be rasterized 
  uint32 points_per_pixel = 2;  // Number of points to keep track of per pixel
}

message MeshRenderParameters {
  float max_mesh_edge = 1;  // Mesh edges longer than this value are discarded
}

message RenderParameters {
  oneof render_parameters {
    PointCloudRenderParameters pointcloud_parameters = 1;
    MeshRenderParameters mesh_parameters = 2;
  }
}

enum CameraType {
  CAMERA_PERSPECTIVE = 0;   // Perspective camera
  CAMERA_ORTHOGRAPHIC = 1;  // Orthographic camera. Well suited for isometric animations
}

message CameraParameters {
  CameraType camera_type = 1;
  float near_plane = 2;    // Nearest plane depth of a rendered frustum
  float far_plane = 3;     // Farthest plane depth of a rendered frustum
  optional float fov = 4;  // Camera field of view (in degrees). Must be set for CAMERA_PERSPECTIVE type.
}

message TransformCameraPose {
  TransformMatrix world_to_view_matrix = 1;  // 4x4 transform matrix for the next frame
  CameraParameters camera_parameters = 2;
  RenderParameters image_render_parameters = 3;
  RenderParameters mask_render_parameters = 4;
  bool do_prefill = 5;   // Prefill masked areas with values matching the colors around the area
}

message TransformParameters {
  oneof transform {
    TransformColorAdjust color_adjust = 2;
    TransformDepthCalc depth_calc = 4;
    TransformResample resample = 5;
    TransformCameraPose camera_pose = 6;
  }
}


//
// Asset parameters
//

enum AssetAction {
  ASSET_PUT = 0;
  ASSET_GET = 1;
  ASSET_DELETE = 2;
}

// AssetUse defines how the asset is used within a project.  This enum matches
// the values the project proto.
enum AssetUse {
  ASSET_USE_UNDEFINED = 0;    // Asset does not have use defined
  ASSET_USE_INPUT = 1;        // Asset is used as an input for the project
  ASSET_USE_OUTPUT = 2;       // Asset is an output from the project
  ASSET_USE_INTERMEDIATE = 3; // Asset is an output from an intermediate step of the project
  ASSET_USE_PROJECT = 4;      // Asset is used as the project file for the project
}

message AssetParameters {
  AssetAction action = 1;
  string project_id = 2;
  AssetUse use = 3;
}

// AnswerMeta is a set of metadata about an answer, usually the operating
// environment.
message AnswerMeta {
  optional string gpu_id = 1;
  optional string cpu_id = 2;
  optional string node_id = 3;
  optional string engine_id = 4;
}

// An Answer is a response to a Request. It is a set of Artifacts, which can be
// of any type and forwarded to the client or the next stage.
message Answer {
  string answer_id = 1;
  string request_id = 2;
  uint64 received = 3;
  uint64 created = 4;
  optional AnswerMeta meta = 6;
  repeated Artifact artifacts = 7;
}

// An AnswerBatch is a set of Answers. It can represent one or several completed
// requests, which may be sent to the client in a single response.
message AnswerBatch {
  string batch_id = 1;
  repeated Answer answers = 2;
}

// A Request is a set of Artifacts, which can be of any type with model or
// transform parameters. It is sent to the server, which will respond with an
// Answer.
message Request {
  string engine_id = 1;
  string request_id = 2;
  ArtifactType requested_type = 3;
  repeated Prompt prompt = 4;
  oneof params {
    ImageParameters image = 5;
    ClassifierParameters classifier = 7;
    AssetParameters asset = 8;
    InterpolateParameters interpolate = 11;
    TransformParameters transform = 12;
  }
  optional ConditionerParameters conditioner = 6;
  reserved 9,10; //9, 10 are reserved
  optional google.protobuf.Struct extras = 2047; // for development use
}

//
// Stages
//
// A Stage is a single step in a pipeline. Stages are a set of Requests, which are
// sent to the server, and a set of Answers, which are received from the server.

enum StageAction {
  STAGE_ACTION_PASS = 0;
  STAGE_ACTION_DISCARD = 1;
  STAGE_ACTION_RETURN = 2;
}

message OnStatus {
  repeated FinishReason reason = 1;
  optional string target = 2;
  repeated StageAction action = 3;
}

message Stage {
  string id = 1;
  Request request = 2;
  repeated OnStatus on_status = 3;
}

message ChainRequest {
  string request_id = 1;
  repeated Stage stage = 2;
}

//
// gRPC services
//
service GenerationService {
  rpc Generate (Request) returns (stream Answer) {};
  rpc ChainGenerate (ChainRequest) returns (stream Answer) {};
}
